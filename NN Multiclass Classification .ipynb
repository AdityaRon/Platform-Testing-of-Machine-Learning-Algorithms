{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network Implementation in Python\n",
    "Python does not have a stable production version of neural netwroks. Multilayer preceptron has been implemented in the DEV region of scikit learn.\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/13547/question-about-neural-networks-in-python\n",
    "\n",
    "The below basic version of Neural Networks has been used for testing these datasets. This is a basic Neural Network(Multi Layer Preceptron) implemented by Issam Lardji. We have used this to test the Neural Network part for these datasets. \n",
    "\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/13547/question-about-neural-networks-in-python\n",
    "https://github.com/IssamLaradji/NeuralNetworks/tree/master/multilayer_perceptron\n",
    "\n",
    "The main file is \"multilayer_perceptron.py\"\n",
    "\n",
    "It contains 3 classes,\n",
    "\n",
    "1) Multi-layer perceptron Classifier (explained in detail in line 562)\n",
    "\n",
    "2) Multi-layer perceptron Regressor (explained in detail in line 830)\n",
    "\n",
    "3) Multi-layer perceptron Autoencoder (explained in detail in line 999)\n",
    "\n",
    "To describe other files present in this repo,\n",
    "\n",
    "- 'base.py' contains the activation functions and their derivatives,\n",
    "and loss functions. \n",
    "\n",
    "- 'autoencoder.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==============================================\n",
    "Using multilayer perceptron for classification\n",
    "==============================================\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, StratifiedShuffleSplit \n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "get_ipython().magic('matplotlib inline')\n",
    "from multilayer_perceptron  import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reading the file\n",
    "def read_file(trainF,testF, Directory, Target_col,transform,drop_cols=None,categ_transform=None):\n",
    "    train = pd.read_csv(Directory + trainF)\n",
    "    test =  pd.read_csv(Directory + testF)\n",
    "    if transform:\n",
    "        lbl_enc = preprocessing.LabelEncoder()\n",
    "        labels = train[Target_col].values\n",
    "        labels = lbl_enc.fit_transform(labels)\n",
    "        labels_test = test[Target_col].values\n",
    "        labels_test = lbl_enc.fit_transform(labels_test)\n",
    "        train.drop([Target_col],axis=1)\n",
    "        test.drop([Target_col],axis=1)\n",
    "        train[Target_col] = labels\n",
    "        test[Target_col] = labels_test\n",
    "    if drop_cols is not None:\n",
    "        for i in drop_cols:\n",
    "            train.drop([i],axis=1,inplace=True)\n",
    "            test.drop([i],axis=1,inplace=True)\n",
    "    if categ_transform is not None:\n",
    "        for j in categ_transform:\n",
    "            lbl_enc = preprocessing.LabelEncoder()\n",
    "            labels = train[j].values\n",
    "            labels = lbl_enc.fit_transform(labels)\n",
    "            labels_test = test[j].values\n",
    "            labels_test = lbl_enc.fit_transform(labels_test)\n",
    "            train.drop([j],axis=1)\n",
    "            test.drop([j],axis=1)\n",
    "            train[j] = labels\n",
    "            test[j] = labels_test\n",
    "            \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLP classifier\n",
    "def mlp_classifier(train, test, accuracy, roc_auc, Target_col):\n",
    "    start_time = timeit.default_timer()\n",
    "    y = train[Target_col]\n",
    "    X = train.drop([Target_col],axis=1)\n",
    "    test_labels = test[Target_col]\n",
    "    test_X = test.drop([Target_col],axis=1)\n",
    "    random_state = np.random.RandomState(0)\n",
    "    # Binarize the output\n",
    "    y = label_binarize(y, classes=np.unique(y))\n",
    "    test_labels = label_binarize(test_labels, classes=np.unique(test_labels))\n",
    "    n_classes = y.shape[1]\n",
    "    classifier = OneVsRestClassifier(MultilayerPerceptronClassifier())\n",
    "    y_score = classifier.fit(X, y).decision_function(test_X)\n",
    "    y_pred = classifier.predict(test_X)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc_dict = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], y_score[:, i])\n",
    "        roc_auc_dict[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_labels.ravel(), y_score.ravel())\n",
    "    roc_auc_dict[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    roc_auc.append(roc_auc_dict[\"micro\"])\n",
    "    accuracy.append(metrics.accuracy_score(test_labels, y_pred))\n",
    "    elapsed = (timeit.default_timer() - start_time)/60\n",
    "    return accuracy, roc_auc, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_build(filenum,Target_column, df_train, df_test, Directory,drop_cols=None,categ_transform=None):\n",
    "    accuracy_mlp = []; roc_auc_mlp = []\n",
    "\n",
    "    elapsed_time_mlp = []\n",
    "    Target_col = Target_column\n",
    "    for i in range(1,8):\n",
    "        trainF = df_train+ str(i) + '.csv'\n",
    "        testF = df_test + str(i) + '.csv'\n",
    "        print(\"Executing this iteration:\",i)\n",
    "        train, test = read_file(trainF,testF,Directory, Target_col,transform=True,drop_cols=drop_cols,categ_transform=categ_transform)\n",
    "        accuracy_mlp, roc_auc_mlp, elapsed = mlp_classifier(train, test, accuracy_mlp, roc_auc_mlp, Target_col)\n",
    "        elapsed_time_mlp.append(elapsed)\n",
    "    \n",
    "    print('Data set# ' + str(filenum))\n",
    "    print('********** MLP classifier ***********')\n",
    "    print('Individual file accuracy for MLP')\n",
    "    print(np.array(accuracy_mlp))\n",
    "    print('Individual time taken for MLP')\n",
    "    print(np.array(elapsed_time_mlp))\n",
    "    print('Accuracy mean   ' + 'Accuracy Stdev  ')\n",
    "    print(np.array(accuracy_mlp).mean(), np.array(accuracy_mlp).std())\n",
    "    print('Individual file AUC for MLP')\n",
    "    print(np.array(roc_auc_mlp))\n",
    "    print('AUC mean        ' + 'AUC      Stdev  ')\n",
    "    print(np.array(roc_auc_mlp).mean(), np.array(roc_auc_mlp).std())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 1\n",
      "Executing this iteration: 2\n",
      "Executing this iteration: 3\n",
      "Executing this iteration: 4\n",
      "Executing this iteration: 5\n",
      "Executing this iteration: 6\n",
      "Executing this iteration: 7\n",
      "Executing this iteration: 8\n",
      "Executing this iteration: 9\n",
      "Executing this iteration: 10\n",
      "Data set# 2\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 0.83754075  0.82665663  0.82856494  0.82470454  0.83335862  0.82774252\n",
      "  0.80306711  0.83522813  0.8293291   0.827693  ]\n",
      "Individual time taken for MLP\n",
      "[ 2.82671993  2.27776472  2.4505404   2.14884537  2.6584539   2.88064055\n",
      "  2.68145415  2.06879917  2.04752805  2.05741541]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.827388534213 0.00897110636985\n",
      "Individual file AUC for MLP\n",
      "[ 0.99625345  0.99630362  0.99614883  0.99586206  0.99570373  0.996129\n",
      "  0.97709168  0.99648595  0.99577334  0.99625746]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.994200911926 0.00570800355794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=2,Target_column='letter', df_train='data2_train', df_test='data2_test', Directory = \"./Data Set 2/splits/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 1\n",
      "Executing this iteration: 2\n",
      "Executing this iteration: 3\n",
      "Executing this iteration: 4\n",
      "Executing this iteration: 5\n",
      "Executing this iteration: 6\n",
      "Executing this iteration: 7\n",
      "Data set# 4\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 0.25345995  0.24105211  0.25841735  0.24682812  0.27353028  0.23759034\n",
      "  0.26203607]\n",
      "Individual time taken for MLP\n",
      "[ 5.73285532  5.32064402  5.58712958  5.39451941  5.82911932  5.49675501\n",
      "  5.36997353]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.253273460146 0.0116525917423\n",
      "Individual file AUC for MLP\n",
      "[ 0.8870963   0.87561797  0.88876083  0.88732455  0.88680122  0.88525504\n",
      "  0.88430609]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.885023142963 0.00406643993565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=4,Target_column='Activity', df_train='data4_train', df_test='data4_test', Directory = \"./Data Set 4/splits/\",drop_cols=['Tag_Identificator'],categ_transform=['Sequence_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 1\n",
      "Executing this iteration: 2\n",
      "Executing this iteration: 3\n",
      "Executing this iteration: 4\n",
      "Executing this iteration: 5\n",
      "Data set# 6\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 0.99017399  0.9943608   0.92260634  0.98818466  0.98877698]\n",
      "Individual time taken for MLP\n",
      "[ 1.02062438  1.03465317  0.63650744  0.74724698  0.66194638]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.9768205546 0.0271928461803\n",
      "Individual file AUC for MLP\n",
      "[ 0.99676289  0.99875995  0.94548276  0.99751025  0.99599856]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.986902880238 0.0207300922048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=6,Target_column='Class', df_train='d6_train', df_test='d6_test', Directory  = \"./Data Set 6/splits/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 1\n",
      "Executing this iteration: 2\n",
      "Executing this iteration: 3\n",
      "Executing this iteration: 4\n",
      "Executing this iteration: 5\n",
      "Executing this iteration: 6\n",
      "Executing this iteration: 7\n",
      "Executing this iteration: 8\n",
      "Executing this iteration: 9\n",
      "Executing this iteration: 10\n",
      "Data set# 7\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 0.31060606  0.3822037   0.63907709  0.5736013   0.7750953   0.62025783\n",
      "  0.60450966  0.5343164   0.78311499  0.19108625]\n",
      "Individual time taken for MLP\n",
      "[ 0.32442025  0.28934027  0.43517719  0.3932628   0.54281516  0.44787463\n",
      "  0.43542585  0.40132342  0.54332185  0.22738988]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.541386858827 0.183084122515\n",
      "Individual file AUC for MLP\n",
      "[ 0.57592062  0.58559139  0.74896941  0.73719188  0.81201548  0.78461015\n",
      "  0.70040851  0.68551372  0.87041347  0.52903197]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.702966660488 0.105054954693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=7,Target_column='Class', df_train='d7_train', df_test='d7_test', Directory = \"./Data Set 7/splits/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 1\n",
      "Executing this iteration: 2\n",
      "Executing this iteration: 3\n",
      "Executing this iteration: 4\n",
      "Executing this iteration: 5\n",
      "Data set# 12\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 0.91666667  0.73333333  0.6         0.75        0.76923077]\n",
      "Individual time taken for MLP\n",
      "[ 0.21586285  0.22866493  0.1980077   0.21280687  0.25355355]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.753846153846 0.100847819554\n",
      "Individual file AUC for MLP\n",
      "[ 1.          0.98777778  0.97444444  0.99316406  0.99260355]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.989597967004 0.00851933322793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=12,Target_column='TARGET', df_train='d12_original_train', df_test='d12_original_test', Directory = \"./Original Dataset_12_Brain/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 7\n",
      "Executing this iteration: 8\n",
      "Executing this iteration: 9\n",
      "Executing this iteration: 10\n",
      "Data set# 12\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 0.92857143  0.83333333  0.64705882  0.45      ]\n",
      "Individual time taken for MLP\n",
      "[ 0.15394472  0.16005637  0.14795043  0.13629909]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.714740896359 0.183341394536\n",
      "Individual file AUC for MLP\n",
      "[ 0.99617347  0.99479167  0.9567474   0.936875  ]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.971146885225 0.0253343282741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=12,Target_column='TARGET', df_train='d12_original_train', df_test='d12_original_test', Directory = \"./Original Dataset_12_Brain/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 1\n",
      "Executing this iteration: 2\n",
      "Executing this iteration: 3\n",
      "Executing this iteration: 4\n",
      "Data set# 14\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 1.          0.94736842  0.95652174  0.89473684]\n",
      "Individual time taken for MLP\n",
      "[ 0.06248331  0.04951722  0.06196375  0.06283128]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.949656750572 0.0374266069423\n",
      "Individual file AUC for MLP\n",
      "[ 1.          0.99722992  1.          0.99630656]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.99838411819 0.0016485291848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=14,Target_column='C2309', df_train='srbct_train', df_test='srbct_test', Directory = \"./data14_srbct/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 6\n",
      "Executing this iteration: 7\n",
      "Executing this iteration: 8\n",
      "Executing this iteration: 9\n",
      "Executing this iteration: 10\n",
      "Data set# 14\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 0.91304348  0.96551724  1.          0.95652174  0.89473684]\n",
      "Individual time taken for MLP\n",
      "[ 0.05806321  0.04375086  0.04649647  0.04610418  0.04793023]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.945963860175 0.0377403414331\n",
      "Individual file AUC for MLP\n",
      "[ 1.          0.99762188  1.          1.          0.99261311]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.998046998088 0.00286881497741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=14,Target_column='C2309', df_train='srbct_train', df_test='srbct_test', Directory = \"./data14_srbct/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing this iteration: 1\n",
      "Executing this iteration: 2\n",
      "Executing this iteration: 3\n",
      "Executing this iteration: 4\n",
      "Executing this iteration: 5\n",
      "Executing this iteration: 6\n",
      "Executing this iteration: 7\n",
      "Executing this iteration: 8\n",
      "Executing this iteration: 9\n",
      "Executing this iteration: 10\n",
      "Data set# 15\n",
      "********** MLP classifier ***********\n",
      "Individual file accuracy for MLP\n",
      "[ 1.          1.          1.          0.95238095  0.91304348  0.94444444\n",
      "  0.95454545  1.          1.          0.94444444]\n",
      "Individual time taken for MLP\n",
      "[ 0.06837549  0.07203662  0.08798808  0.06351131  0.05393646  0.05845205\n",
      "  0.0615529   0.06785157  0.07002609  0.06270093]\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.970885877408 0.0309703797757\n",
      "Individual file AUC for MLP\n",
      "[ 1.          1.          1.          0.99773243  0.99905482  1.\n",
      "  0.99896694  1.          1.          1.        ]\n",
      "AUC mean        AUC      Stdev  \n",
      "0.999575418887 0.000727995344852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=15,Target_column='TARGET', df_train='d15_original_train', df_test='d15_original_test', Directory = \"./Original Dataset_15_Lymphoma/\",drop_cols=None,categ_transform=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
